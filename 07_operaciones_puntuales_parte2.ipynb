{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fRVsaiWyL5X"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrJa2MEVy36w"
      },
      "outputs": [],
      "source": [
        "# conectar a google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f_8tS0XDllY"
      },
      "source": [
        "## Suma de imágenes\n",
        "\n",
        "Logos: https://www.kaggle.com/datasets/kkhandekar/popular-brand-logos-image-dataset\n",
        "\n",
        "1481 popular brand logos\n",
        "\n",
        "UCF-QNRF_ECCV18: https://www.kaggle.com/datasets/kokunsyu/ucf-qnrf-eccv18\n",
        "\n",
        " Dataset utilizado para la tarea de conteo de multitudes (crowd counting). Contiene imágenes de escenas densamente pobladas, como manifestaciones y eventos públicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4TOjAJCFz7H"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar las imágenes\n",
        "imagen_principal = cv2.imread('/content/drive/MyDrive/datos_PDI/logos/img_0002.jpg')\n",
        "logo = cv2.imread('/content/drive/MyDrive/datos_PDI/logos/Heineken-logo-400x400.png')\n",
        "\n",
        "# Convertir las imágenes de BGR a RGB (OpenCV usa BGR por defecto)\n",
        "imagen_principal_rgb = cv2.cvtColor(imagen_principal, cv2.COLOR_BGR2RGB)\n",
        "logo_rgb = cv2.cvtColor(logo, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Obtener el tamaño de la imagen principal\n",
        "alto, ancho = imagen_principal_rgb.shape[:2]\n",
        "\n",
        "# Redimensionar el logo al tamaño de la imagen principal\n",
        "logo_redimensionado = cv2.resize(logo_rgb, (ancho, alto))\n",
        "\n",
        "# Definir pesos para la combinación ponderada\n",
        "peso_imagen_principal = 0.7\n",
        "peso_logo = 1 - peso_imagen_principal\n",
        "\n",
        "# Combinar las imágenes usando una suma ponderada\n",
        "imagen_combinada = cv2.addWeighted(imagen_principal_rgb, peso_imagen_principal, logo_redimensionado, peso_logo, 0)\n",
        "\n",
        "# Mostrar las imágenes usando matplotlib\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title('Imagen Principal')\n",
        "plt.imshow(imagen_principal_rgb)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title('Logo Redimensionado')\n",
        "plt.imshow(logo_redimensionado)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title('Imagen Combinada')\n",
        "plt.imshow(imagen_combinada)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3ogERCoWD0k"
      },
      "source": [
        "## Diferencia de imágenes\n",
        "\n",
        "Ejemplo de substracción de fondo para detección de movimiento e intrusos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NWGYJIgWJNf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ruta del video\n",
        "video_path = '/content/drive/MyDrive/datos_PDI/ladron.mp4'\n",
        "\n",
        "# Abrir el video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Leer los primeros 60 frames para obtener el fondo inicial\n",
        "for _ in range(60):\n",
        "    ret, fondo = cap.read()\n",
        "if not ret:\n",
        "    print(\"Error al leer el video.\")\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    exit()\n",
        "\n",
        "# Convertir el último frame de los primeros 60 frames a escala de grises\n",
        "fondo = cv2.cvtColor(fondo, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Número de frames a procesar\n",
        "num_frames_to_process = 10\n",
        "\n",
        "# Crear una figura con 2 filas y 5 columnas\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "\n",
        "# Convertir el objeto de ejes a una lista para iterar fácilmente\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(num_frames_to_process):\n",
        "    # Dejar pasar 50 frames\n",
        "    for _ in range(50):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "    # Convertir el frame actual a escala de grises\n",
        "    gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calcular la diferencia entre el fondo y el frame actual\n",
        "    diferencia = cv2.absdiff(fondo, gris)\n",
        "\n",
        "    # Aplicar un umbral para obtener una imagen binaria\n",
        "    _, umbral = cv2.threshold(diferencia, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "    # Encontrar contornos en la imagen binaria\n",
        "    contornos, _ = cv2.findContours(umbral, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Inicializar el bounding box más grande\n",
        "    bbox_max = None\n",
        "    max_area = 0\n",
        "    # Iterar sobre todos los contornos para encontrar el bounding box más grande\n",
        "    for contorno in contornos:\n",
        "        (x, y, w, h) = cv2.boundingRect(contorno)\n",
        "        area = w * h\n",
        "        if area > max_area:\n",
        "            max_area = area\n",
        "            bbox_max = (x, y, w, h)\n",
        "    # Dibujar el bounding box más grande\n",
        "    if bbox_max is not None:\n",
        "        (x, y, w, h) = bbox_max\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
        "    # Convertir el frame de BGR a RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    # Mostrar la imagen diferencia entre fondo y actual, en escala de grises\n",
        "    axes[i].imshow(diferencia, cmap='gray')\n",
        "    # Mostrar el frame en la cuadrícula\n",
        "    #axes[i].imshow(frame_rgb)\n",
        "\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# Ajustar el layout para evitar solapamiento\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura con todos los frames\n",
        "plt.show()\n",
        "\n",
        "# Liberar recursos\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentación color y multiplicación"
      ],
      "metadata": {
        "id": "02J7NCrLnFwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Corn or Maize Leaf Disease Dataset**\n",
        "\n",
        "A dataset for classification of corn or maize plant leaf diseases\n",
        "\n",
        "Dataset Description:\n",
        "- 0: Common Rust - 1306 images\n",
        "- 1: Gray Leaf Spot - 574 images\n",
        "- 2: Blight -1146 images\n",
        "- 3: Healthy - 1162 images\n",
        "\n",
        "https://www.kaggle.com/datasets/smaranjitghose/corn-or-maize-leaf-disease-dataset"
      ],
      "metadata": {
        "id": "tM_haRd81HkF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbKZIU1u9e3R"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# Ruta a una imagen de ejemplo\n",
        "image_path = '/content/drive/MyDrive/datos_PDI/Corn_Maize_Leaf/Corn_Health (1023).jpg'\n",
        "\n",
        "# Cargar la imagen\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convertir a espacio de color HSV\n",
        "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Definir los rangos de color para segmentar el color verde\n",
        "# LOCALIZACION EN HSV:\n",
        "# H: 120º en la rueda, pero en OpenCV va de 0-180º --> el G está centrado en 60º\n",
        "# S: desde un rango bajo a máximo (para cubrirnos)\n",
        "# V: ídem S\n",
        "lower_green = np.array([25, 40, 40])\n",
        "upper_green = np.array([80, 255, 255])\n",
        "\n",
        "# Crear una máscara con los colores definidos\n",
        "mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "# Aplicar la máscara a la imagen original\n",
        "segmented_image = cv2.bitwise_and(image_rgb, image_rgb, mask=mask)\n",
        "\n",
        "# Mostrar la imagen original y la segmentada\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Imagen Original')\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Imagen Segmentada')\n",
        "plt.imshow(segmented_image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTAS**\n",
        "\n",
        "- ¿Por qué se producen los huecos en la imagen segmentada?\n",
        "- ¿Qué (buen) comportamiento observa en la segmentación de la imagen saludable 1019?\n",
        "\n",
        "   TIP: está relacionada a la ventaja del desacoplamiento \"cromaticidad / brillo\" que hace el modelo HSV respecto al RGB.\n",
        "- ¿Cómo podría utilizar la segmentación color para hacer un \"clasificador de salud\" de las hojas?"
      ],
      "metadata": {
        "id": "xTa2AmYE3EEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROYECTO"
      ],
      "metadata": {
        "id": "mX7YhfLm5SSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clasificación de frutas**\n",
        "\n",
        "Dataset: \"Fruits fresh and rotten for classification\"\n",
        "\n",
        "(parte del dataset \"Fresh and Rotten Classification\")\n",
        "\n",
        "https://www.kaggle.com/datasets/sriramr/fruits-fresh-and-rotten-for-classification\n",
        "\n"
      ],
      "metadata": {
        "id": "wIXRysoy5T3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Definir las rutas a las carpetas de train y test\n",
        "train_dir = '/content/drive/MyDrive/datos_PDI/Fruits_classification/train'\n",
        "test_dir = '/content/drive/MyDrive/datos_PDI/Fruits_classification/test'\n",
        "classes = ['roja', 'verde']\n",
        "image_size = (100, 100)  # Tamaño al que redimensionaremos las imágenes\n",
        "\n",
        "\n",
        "def cambiar_cercanos_al_blanco_a_negro(img, umbral=240):\n",
        "    \"\"\"\n",
        "    Cambia los valores cercanos al blanco por negro en la imagen.\n",
        "\n",
        "    :param img: Imagen en formato BGR.\n",
        "    :param umbral: Valor del canal de intensidad (V) en HSV. Los píxeles con valores\n",
        "                   de intensidad mayores que este umbral se convertirán en negro.\n",
        "    :return: Imagen con los valores cercanos al blanco cambiados a negro.\n",
        "    \"\"\"\n",
        "    # Convertir la imagen de BGR a HSV\n",
        "    hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    # Crear una máscara donde los valores de intensidad (V) son mayores que el umbral\n",
        "    _, _, V = cv2.split(hsv_image)\n",
        "    mascara = V > umbral\n",
        "    # Crear una imagen de salida donde los valores cercanos al blanco se cambian a negro\n",
        "    imagen_salida = img.copy()\n",
        "    imagen_salida[mascara] = [0, 0, 0]\n",
        "    return imagen_salida\n",
        "\n",
        "# Función para cargar y redimensionar imágenes\n",
        "def load_and_resize_images(base_dir, classes, num_images, size):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for fruit in classes:\n",
        "        for i in range(1, num_images + 1):\n",
        "            img_path = os.path.join(base_dir, f'{fruit}{i}.png')\n",
        "            img = cv2.imread(img_path)\n",
        "            # Verificar que la imagen se ha cargado correctamente\n",
        "            if img is not None:\n",
        "                img = cambiar_cercanos_al_blanco_a_negro(img)\n",
        "                # Redimensionar imagen\n",
        "                img_resized = cv2.resize(img, size)\n",
        "                images.append(img_resized)\n",
        "                labels.append(fruit)\n",
        "            else:\n",
        "                print(f\"ERROR: no se pudo cargar imagen {img_path}\")\n",
        "    return images, labels\n",
        "\n",
        "# Cargar y redimensionar imágenes y etiquetas de entrenamiento (5 imágenes por fruta)\n",
        "train_images, train_labels = load_and_resize_images(train_dir, classes, num_images=5, size=image_size)\n",
        "\n",
        "# Cargar y redimensionar imágenes y etiquetas de prueba (2 imágenes por fruta)\n",
        "test_images, test_labels = load_and_resize_images(test_dir, classes, num_images=2, size=image_size)\n",
        "\n",
        "# Configurar la visualización\n",
        "num_classes = len(classes)\n",
        "num_images_per_class = len([label for label in train_labels if label == classes[0]])\n",
        "\n",
        "plt.figure(figsize=(15, num_classes * 3))  # Ajustar el tamaño según sea necesario\n",
        "\n",
        "for idx, fruit in enumerate(classes):\n",
        "    # Encontrar los índices de las imágenes de la fruta actual\n",
        "    fruit_indices = [i for i, label in enumerate(train_labels) if label == fruit]\n",
        "    # Mostrar todas las imágenes de la fruta en la fila correspondiente\n",
        "    for j, image_idx in enumerate(fruit_indices):\n",
        "        plt.subplot(num_classes, num_images_per_class, idx * num_images_per_class + j + 1)\n",
        "        plt.imshow(cv2.cvtColor(train_images[image_idx], cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        if j == 0:\n",
        "            plt.title(fruit.capitalize())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jpSYpu295TWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images)"
      ],
      "metadata": {
        "id": "osICwYNEZJ-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_images shape: {np.array(train_images).shape}\")"
      ],
      "metadata": {
        "id": "sgkyWKTDZLsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "ZFpShrkcZcrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostrar imagen 1 de train_images, con su label\n",
        "\n",
        "plt.imshow(cv2.cvtColor(train_images[0], cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "train_labels[0]"
      ],
      "metadata": {
        "id": "t4-t1sweZfqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROGRAMAR AQUÍ LA SOLUCIÓN**:"
      ],
      "metadata": {
        "id": "2P9NJtP0Z0zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solución propuesta\n",
        "\n",
        "...."
      ],
      "metadata": {
        "id": "74MnNTL4Z8zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análisis de resultados**\n",
        "\n",
        "Explicar:\n",
        "- Extracción de características: cuál fue la aproximación, pasos seguidos (diagrama en bloque) y parámetros elegidos.\n",
        "- Clasificación: mencionar la técnica utilizada -no explicar teóricamente-.\n",
        "- Evaluación: explicar cómo se llevó a cabo el análisis del rendimiento del modelo (proceso elegido y resultados).\n",
        "- Mostrar algunos ejemplos de predicciones correctas y algunos de incorrectas (si surgieran).\n"
      ],
      "metadata": {
        "id": "ia8sNcBC8QQq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}